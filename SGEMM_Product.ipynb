{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, accuracy_score, roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/manit/OneDrive/Desktop/Masters/Spring20/Sabir/Assignment_2')\n",
    "df = pd.read_csv(\"sgemm_product.csv\")\n",
    "pd.DataFrame.rename(df,columns={'Run1 (ms)':'Run1','Run2 (ms)':'Run2','Run3 (ms)':'Run3', 'Run4 (ms)':'Run4'},inplace =True)\n",
    "df['AvgRun']=df.apply(lambda row:(row.Run1+row.Run2+row.Run3+row.Run4)/4,axis=1)\n",
    "df = df.drop([\"Run1\",\"Run2\",\"Run3\",\"Run4\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_run=np.mean(df[\"AvgRun\"],axis=0)\n",
    "print(avg_run)\n",
    "df[\"run_class\"]=np.where(df['AvgRun']>=avg_run,1,0)\n",
    "y=df[\"run_class\"].astype(\"category\")\n",
    "x=df.iloc[:,0:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7, random_state=1)\n",
    "std_Xtrain = preprocessing.scale(x_train)\n",
    "std_Xtest = preprocessing.scale(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Machines\n",
    "C = [0.01, 0.5, 1, 10]\n",
    "scores = []\n",
    "for i in C:\n",
    "    clf = SVC(C=i, kernel='linear', random_state=1)\n",
    "    cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    scr = cross_val_score(clf, std_Xtrain, y_train, cv=cv)\n",
    "    print(round(scr.mean(), 5))\n",
    "    scores.append(round(scr.mean(), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(C, scores, color='red',lw=2)\n",
    "plt.xticks([0.01, 1, 5, 10])\n",
    "plt.xlabel(\"Penalty Parameter C\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "svclassifier = SVC(kernel='linear', probability=True, random_state=1, C=0.5)\n",
    "svclassifier.fit(std_Xtrain, y_train)\n",
    "ypred = svclassifier.predict(std_Xtest)\n",
    "print(confusion_matrix(y_test, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,ypred))\n",
    "print(round(accuracy_score(y_test, ypred), 5))\n",
    "prob = svclassifier.predict_proba(std_Xtest)[:, 1]\n",
    "fpr,tpr,thresholds = roc_curve(y_test, prob, pos_label=1)\n",
    "tpr\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr, tpr, linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "\n",
    "plt.show()\n",
    "ROC_AUC = roc_auc_score(y_test, prob)\n",
    "round(ROC_AUC, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polynomial Kernel\n",
    "degree = [2, 3, 4, 5]\n",
    "scores1 = []\n",
    "for i in degree:\n",
    "    clf1 = SVC(C=1, kernel='poly', degree=i, random_state=1, gamma='auto')\n",
    "    cv1 = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    scr1 = cross_val_score(clf1, std_Xtrain, y_train, cv=cv1)\n",
    "    print(round(scr1.mean(), 5))\n",
    "    scores1.append(round(scr1.mean(), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(degree, scores1, color='red',lw=2)\n",
    "plt.xticks([2, 3, 4, 5])\n",
    "plt.xlabel(\"Degree of polynomial\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "svclassifier1 = SVC(kernel='poly', degree=3, probability=True)\n",
    "svclassifier1.fit(std_Xtrain, y_train)\n",
    "ypred1 = svclassifier1.predict(std_Xtest)\n",
    "print(confusion_matrix(y_test, ypred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,ypred))\n",
    "print(round(accuracy_score(y_test, ypred1), 5))\n",
    "prob1 = svclassifier1.predict_proba(std_Xtest)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, prob1, pos_label=1)\n",
    "tpr\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr, tpr, linewidth=2)                                                                             \n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "\n",
    "plt.show()\n",
    "ROC_AUC = roc_auc_score(y_test, prob1)\n",
    "round(ROC_AUC, 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Radial Basis Kernel\n",
    "C = [0.01, 0.5, 1, 10]\n",
    "scores2 = []\n",
    "for i in C:\n",
    "    clf2 = SVC(kernel='rbf', random_state=1, C=i)\n",
    "    cv2 = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    scr2 = cross_val_score(clf2, std_Xtrain, y_train, cv=cv2)\n",
    "    print(round(scr2.mean(), 5))\n",
    "    scores2.append(round(scr2.mean(), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(C, scores2, color='red',lw=2)\n",
    "plt.xticks([0.01, 1, 5, 10])\n",
    "plt.xlabel(\"Penalty term - C\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "svclassifier2 = SVC(kernel='rbf', probability=True, C=10)\n",
    "svclassifier2.fit(std_Xtrain, y_train)\n",
    "ypred2 = svclassifier2.predict(std_Xtest)\n",
    "print(confusion_matrix(y_test, ypred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,ypred))\n",
    "print(round(accuracy_score(y_test, ypred2), 2))\n",
    "prob2 = svclassifier2.predict_proba(std_Xtest)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, prob2, pos_label=1)\n",
    "tpr\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr, tpr, linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "\n",
    "plt.show()\n",
    "ROC_AUC = roc_auc_score(y_test, prob2)\n",
    "round(ROC_AUC, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Algorithm\n",
    "clf_entropy = DecisionTreeClassifier(criterion=\"entropy\", random_state=10)\n",
    "clf_entropy.fit(std_Xtrain, y_train)\n",
    "y_pred = clf_entropy.predict(std_Xtest)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(round(accuracy_score(y_test, y_pred)*100,5))\n",
    "clf_cv = DecisionTreeClassifier(criterion=\"entropy\", random_state=10)\n",
    "cv = KFold(n_splits=10, random_state=10, shuffle=True)\n",
    "scr = cross_val_score(clf_cv, std_Xtrain, y_train, cv=cv)\n",
    "print(round(scr.mean(),5))\n",
    "depth = list(range(2,27 + 1,1))\n",
    "dpth_scores = []\n",
    "for i in depth:\n",
    "    clf_cv = DecisionTreeClassifier(criterion=\"entropy\", random_state=10, max_depth=i)\n",
    "    cv = KFold(n_splits=5, random_state=10, shuffle=True)\n",
    "    scr = cross_val_score(clf_cv, std_Xtrain, y_train, cv=cv)\n",
    "    print(round(scr.mean(), 5))\n",
    "    dpth_scores.append(round(scr.mean(), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpth_scores1 = []\n",
    "for i in depth:\n",
    "    clf_train = DecisionTreeClassifier(criterion=\"entropy\", random_state=10, max_depth=i)\n",
    "    clf_train.fit(std_Xtrain, y_train)\n",
    "    y_pred1 = clf_train.predict(std_Xtrain)\n",
    "    print(round(accuracy_score(y_train, y_pred1), 5))\n",
    "    dpth_scores1.append(round(accuracy_score(y_train, y_pred1), 5))\n",
    "plt.figure()\n",
    "plt.plot(depth, dpth_scores, dpth_scores1)\n",
    "plt.xticks([2, 5, 8, 10, 12, 15, 17, 20, 23, 25, 27])\n",
    "plt.legend([\"Cross validation accuracy\", \"Training Accuracy\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Depth=15\n",
    "clf_entropy = DecisionTreeClassifier(criterion=\"entropy\", random_state=10, max_depth=7)\n",
    "clf_entropy.fit(std_Xtrain, y_train)\n",
    "y_pred = clf_entropy.predict(std_Xtest)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(round(accuracy_score(y_test, y_pred) * 100, 5))\n",
    "classification_report(y_test, y_pred)\n",
    "probs = clf_entropy.predict_proba(x_test)[:, 1]\n",
    "fpr, tpr, th = roc_curve(y_test, probs, pos_label=1)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr, tpr, linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "\n",
    "plt.show()\n",
    "ROC_AUC = roc_auc_score(y_test, probs)\n",
    "round(ROC_AUC, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient boosting Algorithm\n",
    "n_estimate = [20, 50, 70, 100]\n",
    "est_scores = []\n",
    "for n in n_est:\n",
    "    gb_clf = GradientBoostingClassifier(random_state=10, n_estimators=n)\n",
    "    cv = KFold(n_splits=5, random_state=10, shuffle=True)\n",
    "    scr_b = cross_val_score(gb_clf, std_Xtrain, y_train, cv=cv)\n",
    "    est_scores.append(round(scr_b.mean(), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(n_estimate, est_scores)\n",
    "plt.xticks([20, 50, 70, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "alpha_scores = []\n",
    "for a in alpha:\n",
    "    gb_clf = GradientBoostingClassifier(random_state=10, n_estimators=100, learning_rate=a)\n",
    "    cv = KFold(n_splits=5, random_state=10, shuffle=True)\n",
    "    scr_b = cross_val_score(gb_clf, std_Xtrain, y_train, cv=cv)\n",
    "    print(round(scr_b.mean(), 5))\n",
    "    alpha_scores.append(round(scr_b.mean(), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(alpha, alpha_scores)\n",
    "plt.xticks([0.1, 0.5, 0.75, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = list(range(2, 10 + 1, 1))\n",
    "dpth_scores1 = []\n",
    "for i in depth:\n",
    "    gb_clf = GradientBoostingClassifier(random_state=10, n_estimators=100, learning_rate=0.75, max_depth=i)\n",
    "    cv = KFold(n_splits=5, random_state=10, shuffle=True)\n",
    "    scr = cross_val_score(gb_clf, std_Xtrain, y_train, cv=cv)\n",
    "    print(round(scr.mean(), 5))\n",
    "    dpth_scores1.append(round(scr.mean(), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = list(range(2, 10 + 1, 1))\n",
    "dpth_scores = []\n",
    "for i in depth:\n",
    "    gb_clf = GradientBoostingClassifier(random_state=10, n_estimators=100, learning_rate=0.75, max_depth=i)\n",
    "    gb_clf.fit(std_Xtrain, y_train)\n",
    "    print(round(gb_clf.score(std_Xtrain, y_train), 5))\n",
    "    dpth_scores.append(round(gb_clf.score(std_Xtrain, y_train), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(depth, dpth_scores)\n",
    "plt.plot(depth, dpth_scores1)\n",
    "plt.xticks([2, 4, 6, 8, 10])\n",
    "plt.legend([\"Training Accuracy\", \"Cross validation accuracy\"])\n",
    "plt.show()\n",
    "gb_clf = GradientBoostingClassifier(random_state=10, n_estimators=100, learning_rate=0.75, max_depth=3)\n",
    "gb_clf.fit(std_Xtrain, y_train)\n",
    "y_pred = gb_clf.predict(std_Xtest)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(round(accuracy_score(y_test, y_pred)*100,5))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = gb_clf.predict_proba(std_Xtest)[:, 1]\n",
    "fpr, tpr, th = roc_curve(y_test, probs, pos_label=1)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr, tpr, linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "\n",
    "plt.show()\n",
    "ROC_AUC = roc_auc_score(y_test, probs)\n",
    "round(ROC_AUC, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for the Dataset 1\n",
    "objects = ('SVM Linear', 'SVM Polynomial', 'SVM Radial', 'Decison Tree', 'Gradient Boosintg')\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = [0.93255, 0.96133, 0.98, 0.9358, 0.9632]\n",
    "plt.barh(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.yticks(y_pos, objects)\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Algorithms')\n",
    "plt.title('Comparison of all models')\n",
    "for i, v in enumerate(performance):\n",
    "    plt.text(v + 0.001, i, str(v), color='blue', ha='right', va='center')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curves for first dataset\n",
    "svclassifier = SVC(kernel='linear', probability=True, random_state=1, C=0.5)\n",
    "svclassifier.fit(std_Xtrain, y_train)\n",
    "prob1 = svclassifier.predict_proba(std_Xtest)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial kernel\n",
    "svclassifier1 = SVC(kernel='poly', degree=3, probability=True)\n",
    "svclassifier1.fit(std_Xtrain, y_train)\n",
    "prob2 = svclassifier1.predict_proba(std_Xtest)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radial Basis Kernel\n",
    "svclassifier2 = SVC(kernel='rbf', probability=True, C=10)\n",
    "svclassifier2.fit(std_Xtrain, y_train)\n",
    "prob3 = svclassifier2.predict_proba(std_Xtest)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth=15\n",
    "clf_entropy = DecisionTreeClassifier(criterion=\"entropy\", random_state=10, max_depth=15)\n",
    "clf_entropy.fit(std_Xtrain1, y_train1)\n",
    "prob4 = clf_entropy.predict_proba(std_Xtest1)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf = GradientBoostingClassifier(random_state=10, n_estimators=100, learning_rate=0.75, max_depth=3)\n",
    "gb_clf.fit(std_Xtrain, y_train)\n",
    "prob5 = gb_clf.predict_proba(std_Xtest)[:, 1]\n",
    "\n",
    "fpr1, tpr1, th1 = roc_curve(y_test, prob1, pos_label=1)\n",
    "fpr2, tpr2, th2 = roc_curve(y_test, prob2, pos_label=1)\n",
    "fpr3, tpr3, th3 = roc_curve(y_test, prob3, pos_label=1)\n",
    "fpr4, tpr4, th4 = roc_curve(y_test, prob4, pos_label=1)\n",
    "fpr5, tpr5, th5 = roc_curve(y_test, prob5, pos_label=1)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.plot(fpr1, tpr1, linewidth=2)\n",
    "plt.plot(fpr2, tpr2, linewidth=2)\n",
    "plt.plot(fpr3, tpr3, linewidth=2)\n",
    "plt.plot(fpr4, tpr4, linewidth=2)\n",
    "plt.plot(fpr5, tpr5, linewidth=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve comparison for all Algorithms')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.legend([\"SVM-Linear_AUC=0.96947\", \"SVM-Polynomial_AUC=0.9849\", \"SVM-Radial_AUC=0.99845\", \"DecisonTree_AUC= 0.5\",\n",
    "     \"GradientBoosting_AUC= 0.9882\"])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
